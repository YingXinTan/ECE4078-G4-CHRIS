# evaluate the map generated by SLAM against the true map
import ast
import numpy as np
import json
import matplotlib.pyplot as plt

# utility functions
from TargetPoseEst import estimate_fruits_pose
from CV_eval import CV_eval

def parse_groundtruth(fname : str) -> dict:
    with open(fname, 'r') as f:
        try:
            gt_dict = json.load(f)                   
        except ValueError as e:
            with open(fname, 'r') as f:
                gt_dict = ast.literal_eval(f.readline()) 
        
        aruco_dict = {}
        fruit_dict = {}
        for key in gt_dict:
            if key.startswith("aruco"):
                aruco_num = int(key.strip('aruco')[:-2])
                aruco_dict[aruco_num] = np.reshape([gt_dict[key]["x"], gt_dict[key]["y"]], (2,1))
            else:
                fruit_dict[key[:-2]] =  np.reshape([gt_dict[key]["x"], gt_dict[key]["y"]], (2,1))        
    return aruco_dict, fruit_dict

def parse_user_map(fname : str) -> dict:
    with open(fname, 'r') as f:
        try:
            usr_dict = json.load(f)                   
        except ValueError as e:
            with open(fname, 'r') as f:
                usr_dict = ast.literal_eval(f.readline()) 
        
        # load aruco position
        aruco_dict = {}
        for (i, tag) in enumerate(usr_dict["taglist"]):
            aruco_dict[tag] = np.reshape([usr_dict["map"][0][i],usr_dict["map"][1][i]], (2,1))
        
        # load final robot pose
        final_robot_pose = []
        for (i, tag) in enumerate(usr_dict["final_robot_pose"]):
            final_robot_pose.append(tag[0])

    return aruco_dict, np.hstack(final_robot_pose)

def parse_user_fruits(fname : str) -> dict:
    with open(fname, 'r') as f:
        try:
            t_dict = json.load(f)                  
        except ValueError as e:
            with open(fname, 'r') as f:
                t_dict = ast.literal_eval(f.readline()) 
        trgt_dict = {}
        for frt in t_dict.keys():
            trgt_dict[frt[:-2]] = np.reshape([t_dict[frt]["x"],t_dict[frt]["y"]], (2,1))
    return trgt_dict

def match_aruco_points(aruco0 : dict, aruco1 : dict):
    points0 = []
    points1 = []
    keys = []
    for key in aruco0:
        if not key in aruco1:
            continue
        
        points0.append(aruco0[key])
        points1.append(aruco1[key])
        keys.append(key)
    return keys, np.hstack(points0), np.hstack(points1)

def match_fruit_points(fruit0 : dict, fruit1 : dict):
    points0 = []
    points1 = []
    keys = []
    for key in fruit0:
        if not key in fruit1:
            continue
        
        points0.append(fruit0[key])
        points1.append(fruit1[key])
        keys.append(key)
    return keys, np.hstack(points0), np.hstack(points1)

def solve_umeyama2d(points1, points2):
    # Solve the optimal transform such that
    # R(theta) * p1_i + t = p2_i

    assert(points1.shape[0] == 2)
    assert(points1.shape[0] == points2.shape[0])
    assert(points1.shape[1] == points2.shape[1])


    # Compute relevant variables
    num_points = points1.shape[1]
    mu1 = 1/num_points * np.reshape(np.sum(points1, axis=1),(2,-1))
    mu2 = 1/num_points * np.reshape(np.sum(points2, axis=1),(2,-1))
    sig1sq = 1/num_points * np.sum((points1 - mu1)**2.0)
    sig2sq = 1/num_points * np.sum((points2 - mu2)**2.0)
    Sig12 = 1/num_points * (points2-mu2) @ (points1-mu1).T

    # Use the SVD for the rotation
    U, d, Vh = np.linalg.svd(Sig12)
    S = np.eye(2)
    if np.linalg.det(Sig12) < 0:
        S[-1,-1] = -1
    
    # Return the result as an angle and a 2x1 vector
    R = U @ S @ Vh
    theta = np.arctan2(R[1,0],R[0,0])
    x = mu2 - R @ mu1

    return theta, x

def apply_transform(theta, x, points):
    # Apply an SE(2) transform to a set of 2D points
    assert(points.shape[0] == 2)
    
    c, s = np.cos(theta), np.sin(theta)
    R = np.array(((c, -s), (s, c)))

    points_transformed =  R @ points + x
    return points_transformed


# transformation without ground truth
def transform_without_gt(actual_state, slam_state):
    # actual_state = actual pose of robot
    # slam_state = belief pose of robot    
    theta = actual_state[2] - slam_state[2]
    c, s = np.cos(theta), np.sin(theta)
    R = np.array(((c, -s), (s, c)))
    x = np.array([[actual_state[0] ],[actual_state[1]]]) - R @ np.array([[slam_state[0]],[slam_state[1]]])    
    return theta, x


def compute_rmse(points1, points2):
    # Compute the RMSE between two matched sets of 2D points.
    assert(points1.shape[0] == 2)
    assert(points1.shape[0] == points2.shape[0])
    assert(points1.shape[1] == points2.shape[1])
    num_points = points1.shape[1]
    residual = (points1-points2).ravel()
    MSE = 1.0/num_points * np.sum(residual**2)

    return np.sqrt(MSE)


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser("Matching the estimated map and the true map")
    parser.add_argument("--groundtruth", default='TRUEMAP.txt')
    parser.add_argument("--estimate", default='lab_output/slam_ARUCO.txt')
    # parser.add_argument("--fruit_estimate", default='lab_output/targets.txt')

    # 1 = apply transform, 0 otherwise
    parser.add_argument("--tf", type=int, default=0)
    args = parser.parse_args()

    # gt_fname = "TRUEMAP.txt"
    # est_fname = "lab_output/slam.txt"
    gt_aruco, gt_fruit = parse_groundtruth(args.groundtruth)
    us_aruco, final_robot_pose = parse_user_map(args.estimate)

    # aruco
    taglist, us_vec, gt_vec = match_aruco_points(us_aruco, gt_aruco)
    idx = np.argsort(taglist)
    taglist = np.array(taglist)[idx]
    us_vec = us_vec[:,idx]
    gt_vec = gt_vec[:, idx]

    # fruit
    # estimate_fruits_pose()      # generate targets.txt
    # us_fruit = parse_user_fruits(args.fruit_estimate)
    # fruitlist, us_frt_vec, gt_frt_vec = match_fruit_points(us_fruit, gt_fruit)

    # fruits settled by CV_eval???


    if args.tf == 1:
        # transform with actual final robot pose
        x, y, rad = 0.0, 0.0, 0.0
        x = input("X coordinate of the robot at final position: ")
        try:
            x = float(x)
        except ValueError:
            print("Please enter a number.")

        y = input("Y coordinate of the robot at final position: ")
        try:
            y = float(y)
        except ValueError:
            print("Please enter a number.")

        deg = input("Angle (deg) of the robot at final position: ")
        try:
            rad = np.deg2rad(float(deg))
        except ValueError:
            print("Please enter a number.")

        actual_final_robot_pose = np.hstack([x, y,rad])
        theta, x = transform_without_gt(actual_final_robot_pose, final_robot_pose)
        us_vec_aligned = apply_transform(theta, x, us_vec)
        # us_fruit_aligned = apply_transform(theta, x, us_frt_vec)

        print()
        print("The following parameters transform the estimated points using the actual final robot pose.")
        print("Rotation Angle: {}".format(theta))
        print("Translation Vector: ({}, {})".format(x[0,0], x[1,0]))
    elif args.tf == 0:
        # no transform
        us_vec_aligned = us_vec
        # us_fruit_aligned = us_frt_vec


    # optimal transformation (using ground truth)
    optimal_theta, optimal_x = solve_umeyama2d(us_vec, gt_vec)
    optimal_us_vec_aligned = apply_transform(optimal_theta, optimal_x, us_vec)
    # optimal_us_frt_aligned = apply_transform(optimal_theta, optimal_x, us_frt_vec)

    
    # compare transformed ARUCO state with ground truth (TRUEMAP)
    diff = gt_vec - us_vec_aligned
    rmse = compute_rmse(us_vec, gt_vec)
    rmse_aligned = compute_rmse(us_vec_aligned, gt_vec)
    optimal_rmse_aligned = compute_rmse(optimal_us_vec_aligned, gt_vec)

    # # compare transformed FRUIT state with ground truth (TRUEMAP)
    # diff_frt = gt_frt_vec - us_fruit_aligned
    # rmse_frt = compute_rmse(us_frt_vec, gt_frt_vec)
    # rmse_aligned_frt = compute_rmse(us_fruit_aligned, gt_frt_vec)
    # optimal_rmse_aligned_frt = compute_rmse(optimal_us_frt_aligned, gt_frt_vec)


    # Generate estimated map
    est_map = {}
    # ARUCO
    for (i, tag) in enumerate(taglist):
        coords = {
            "x": us_vec_aligned[0][i],
            "y": us_vec_aligned[1][i]
            }
        est_map[f'aruco{tag}_0'] = coords    
    # # fruits
    # for (i, fruit_name) in enumerate(fruitlist):
    #     coords = {
    #         "x": us_fruit_aligned[0][i],
    #         "y": us_fruit_aligned[1][i]
    #         }
    #     est_map[f'{fruit_name}_0'] = coords
    
    # # update targets.txt with transformed(aligned) fruit position
    # fruit_map = {}
    # for (i, fruit_name) in enumerate(fruitlist):
    #     coords = {
    #         "x": us_fruit_aligned[0][i],
    #         "y": us_fruit_aligned[1][i]
    #         }
    #     fruit_map[f'{fruit_name}_0'] = coords
    # with open("lab_output/targets.txt", 'w') as map_f:
    #     json.dump(fruit_map, map_f, indent=2)
    


    print()
    print("ARUCO")
    print("Number of found markers: {}".format(len(taglist)))
    print("RMSE before alignment: {}".format(rmse))
    print("(robot pose TF) RMSE after alignment:  {}".format(rmse_aligned))
    print("(umeyama TF) RMSE after alignment:  {}".format(optimal_rmse_aligned))
    map_score = (0.2-optimal_rmse_aligned)/(0.2-0.05)*16 + len(taglist)*0.4
    print(f'Map score: {map_score} / 20')

    # print()
    # print("FRUIT")
    # print("Number of found fruits: {}".format(len(fruitlist)))
    # print("RMSE before alignment: {}".format(rmse_frt))
    # print("(robot pose TF) RMSE after alignment:  {}".format(rmse_aligned_frt))
    # print("(umeyama TF) RMSE after alignment:  {}".format(optimal_rmse_aligned_frt))
    # avg_estimate_error = CV_eval()  # get fruit estimation error on the UPDATED targets.txt
    # target_score = (1-avg_estimate_error)/(1-0.025)*16 + len(fruitlist)*0.8
    # print(f'Target score: {target_score} / 20')
    


    # plot to visualize
    ax = plt.gca()

    # ARUCO
    ax.scatter(gt_vec[0,:], gt_vec[1,:], marker='o', color='C0', s=100)
    ax.scatter(us_vec_aligned[0,:], us_vec_aligned[1,:], marker='x', color='C1', s=100)

    # # FRUIT
    # ax.scatter(gt_frt_vec[0,:], gt_frt_vec[1,:], marker='o', color='C2', s=100)
    # ax.scatter(us_fruit_aligned[0,:], us_fruit_aligned[1,:], marker='x', color='C3', s=100)

    # ARUCO
    for i in range(len(taglist)):
        ax.text(gt_vec[0,i]+0.05, gt_vec[1,i]+0.05, taglist[i], color='C0', size=12)
        ax.text(us_vec_aligned[0,i]+0.05, us_vec_aligned[1,i]+0.05, taglist[i], color='C1', size=12)
    
    # # FRUIT
    # for i in range(len(fruitlist)):
    #     ax.text(gt_frt_vec[0,i]+0.05, gt_frt_vec[1,i]+0.05, fruitlist[i], color='C2', size=12)
    #     ax.text(us_fruit_aligned[0,i]+0.05, us_fruit_aligned[1,i]+0.05, fruitlist[i], color='C3', size=12)

    plt.title('Arena')
    plt.xlabel('X') 
    plt.ylabel('Y')
    ax.set_xticks([-1.6, -1.2, -0.8, -0.4, 0, 0.4, 0.8, 1.2, 1.6])
    ax.set_yticks([-1.6, -1.2, -0.8, -0.4, 0, 0.4, 0.8, 1.2, 1.6])
    plt.legend(['Real','Pred'])
    plt.grid()
    plt.show()
    
    # save estimated map as EST_ARUCO.txt
    with open("EST_ARUCO.txt", 'w') as map_f:
        json.dump(est_map, map_f, indent=2)
